{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b375812",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "PyTorch Geometric is not pre-installed on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric\n",
    "!pip install -q torch-geometric torch-scatter torch-sparse\n",
    "\n",
    "print(\"âœ“ Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744399c",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check environment\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0e283",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Adjust these parameters if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'output_dir': '/kaggle/working/cora_gwm_data',\n",
    "    'bert_model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'num_hops': 5,\n",
    "    'sample_size': 5,  # Max neighbors to sample per hop\n",
    "    'embedding_dim': 2048,  # Target dimension for GWM-E\n",
    "    'test_size': 0.2,  # 20% test split\n",
    "    'random_state': 42,  # For reproducibility\n",
    "    'batch_size': 32,  # BERT encoding batch size\n",
    "}\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CONFIG['device'] = device\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c2903",
   "metadata": {},
   "source": [
    "## 4. Download Raw Cora Dataset\n",
    "\n",
    "Download from HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"STEP 1: Downloading Raw Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "repo_id = \"Graph-COM/Text-Attributed-Graphs\"\n",
    "filename = \"cora/processed_data.pt\"\n",
    "raw_dir = Path(\"/kaggle/temp/cora_raw\")\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "dest_file = raw_dir / \"data.pt\"\n",
    "\n",
    "if dest_file.exists():\n",
    "    print(f\"âœ“ Raw data already exists at {dest_file}\")\n",
    "else:\n",
    "    print(f\"Downloading from {repo_id}...\")\n",
    "    downloaded_path = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=filename,\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Copying to {dest_file}...\")\n",
    "    shutil.copy(downloaded_path, dest_file)\n",
    "\n",
    "# Load and verify\n",
    "print(\"\\nLoading dataset...\")\n",
    "data = torch.load(dest_file, weights_only=False)\n",
    "\n",
    "print(f\"\\nâœ“ Successfully loaded Cora dataset!\")\n",
    "print(f\"  Nodes: {data.num_nodes:,}\")\n",
    "print(f\"  Edges: {data.edge_index.size(1):,}\")\n",
    "print(f\"  Classes: {len(data.label_texts)}\")\n",
    "print(f\"  Class names: {data.label_texts}\")\n",
    "print(f\"  Has text: {hasattr(data, 'raw_texts')}\")\n",
    "\n",
    "if not hasattr(data, 'raw_texts'):\n",
    "    raise ValueError(\"Dataset missing 'raw_texts' attribute!\")\n",
    "\n",
    "print(f\"\\nExample node text:\")\n",
    "print(f\"  {data.raw_texts[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c8063d",
   "metadata": {},
   "source": [
    "## 5. Generate BERT Embeddings\n",
    "\n",
    "Encode all node texts using BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"STEP 2: Generating BERT Embeddings\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Loading BERT model: {CONFIG['bert_model']}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['bert_model'])\n",
    "bert_model = AutoModel.from_pretrained(CONFIG['bert_model']).to(device)\n",
    "bert_model.eval()\n",
    "\n",
    "print(f\"âœ“ Model loaded on {device}\")\n",
    "\n",
    "# Generate embeddings\n",
    "all_embeddings = []\n",
    "batch_size = CONFIG['batch_size']\n",
    "\n",
    "print(f\"\\nEncoding {len(data.raw_texts):,} texts (batch_size={batch_size})...\")\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(data.raw_texts), batch_size), desc=\"BERT encoding\"):\n",
    "        batch_texts = data.raw_texts[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        # Get embeddings (mean pooling)\n",
    "        outputs = bert_model(**encoded)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "node_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "print(f\"\\nâœ“ Generated embeddings shape: {node_embeddings.shape}\")\n",
    "\n",
    "# Pad/truncate to target dimension\n",
    "current_dim = node_embeddings.shape[1]\n",
    "target_dim = CONFIG['embedding_dim']\n",
    "\n",
    "if current_dim < target_dim:\n",
    "    padding = torch.zeros(node_embeddings.shape[0], target_dim - current_dim)\n",
    "    node_embeddings = torch.cat([node_embeddings, padding], dim=1)\n",
    "    print(f\"  Padded from {current_dim} to {target_dim} dimensions\")\n",
    "elif current_dim > target_dim:\n",
    "    node_embeddings = node_embeddings[:, :target_dim]\n",
    "    print(f\"  Truncated from {current_dim} to {target_dim} dimensions\")\n",
    "\n",
    "print(f\"\\nâœ“ Final embeddings shape: {node_embeddings.shape}\")\n",
    "\n",
    "# Free GPU memory\n",
    "del bert_model, tokenizer\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"âœ“ Freed GPU memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0b7f0",
   "metadata": {},
   "source": [
    "## 6. Create Multi-hop Graph Embeddings\n",
    "\n",
    "Aggregate node embeddings from k-hop neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaae348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"STEP 3: Creating Multi-hop Embeddings\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "num_nodes = data.num_nodes\n",
    "embedding_dim = node_embeddings.shape[1]\n",
    "num_hops = CONFIG['num_hops']\n",
    "sample_size = CONFIG['sample_size']\n",
    "\n",
    "# Initialize multi-hop embeddings\n",
    "multi_hop_embs = torch.zeros(num_hops, num_nodes, embedding_dim)\n",
    "\n",
    "print(f\"Building {num_hops}-hop neighborhoods for {num_nodes:,} nodes...\")\n",
    "print(f\"Sampling up to {sample_size} neighbors per hop\\n\")\n",
    "\n",
    "for node_idx in tqdm(range(num_nodes), desc=\"Creating multi-hop embeddings\"):\n",
    "    for hop in range(num_hops):\n",
    "        if hop == 0:\n",
    "            # Hop 0: Use the node's own embedding\n",
    "            multi_hop_embs[hop, node_idx] = node_embeddings[node_idx]\n",
    "        else:\n",
    "            # Get k-hop subgraph\n",
    "            subset, _, _, _ = k_hop_subgraph(\n",
    "                node_idx=node_idx,\n",
    "                num_hops=hop,\n",
    "                edge_index=data.edge_index,\n",
    "                relabel_nodes=False,\n",
    "                num_nodes=num_nodes\n",
    "            )\n",
    "            \n",
    "            # Exclude the center node itself\n",
    "            neighbors = [n for n in subset.tolist() if n != node_idx]\n",
    "            \n",
    "            if len(neighbors) > 0:\n",
    "                # Sample neighbors if there are too many\n",
    "                if len(neighbors) > sample_size:\n",
    "                    sampled_neighbors = torch.tensor(\n",
    "                        np.random.choice(neighbors, sample_size, replace=False)\n",
    "                    )\n",
    "                else:\n",
    "                    sampled_neighbors = torch.tensor(neighbors)\n",
    "                \n",
    "                # Aggregate neighbor embeddings (mean pooling)\n",
    "                neighbor_embs = node_embeddings[sampled_neighbors]\n",
    "                multi_hop_embs[hop, node_idx] = neighbor_embs.mean(dim=0)\n",
    "            else:\n",
    "                # No neighbors at this hop: use the node's own embedding\n",
    "                multi_hop_embs[hop, node_idx] = node_embeddings[node_idx]\n",
    "\n",
    "print(f\"\\nâœ“ Multi-hop embeddings shape: {multi_hop_embs.shape}\")\n",
    "print(f\"  Expected: [{num_hops}, {num_nodes}, {embedding_dim}]\")\n",
    "print(f\"\\nEmbedding structure:\")\n",
    "print(f\"  - Hop 0: Node itself\")\n",
    "print(f\"  - Hop 1-{num_hops-1}: Aggregated k-hop neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55d99c",
   "metadata": {},
   "source": [
    "## 7. Split Data and Create Conversations\n",
    "\n",
    "Create train/test split and format as conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"STEP 4: Creating Train/Test Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Split data\n",
    "print(\"Splitting into train/test sets...\")\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(data.num_nodes),\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=CONFIG['random_state'],\n",
    "    stratify=data.y.cpu().numpy()\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Split complete:\")\n",
    "print(f\"  Training samples: {len(train_idx):,}\")\n",
    "print(f\"  Test samples: {len(test_idx):,}\")\n",
    "print(f\"  Split ratio: {1-CONFIG['test_size']:.0%} / {CONFIG['test_size']:.0%}\")\n",
    "\n",
    "# Create conversations\n",
    "def create_conversations(indices, data):\n",
    "    conversations = []\n",
    "    for idx in tqdm(indices, desc=\"Creating conversations\"):\n",
    "        node_id = int(idx)\n",
    "        label_idx = int(data.y[node_id].item())\n",
    "        label_name = data.label_texts[label_idx]\n",
    "        node_text = data.raw_texts[node_id]\n",
    "        \n",
    "        conversations.append({\n",
    "            \"id\": [node_id],\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"What category does this paper belong to? Paper: {node_text}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": label_name\n",
    "                }\n",
    "            ],\n",
    "            \"graph\": 1\n",
    "        })\n",
    "    return conversations\n",
    "\n",
    "print(\"\\nCreating conversation data...\")\n",
    "train_conversations = create_conversations(train_idx, data)\n",
    "test_conversations = create_conversations(test_idx, data)\n",
    "\n",
    "print(f\"\\nâœ“ Created {len(train_conversations):,} train + {len(test_conversations):,} test conversations\")\n",
    "\n",
    "# Show class distribution\n",
    "print(\"\\nClass distribution (train):\")\n",
    "train_labels = [data.y[i].item() for i in train_idx]\n",
    "for i, label in enumerate(data.label_texts):\n",
    "    count = train_labels.count(i)\n",
    "    print(f\"  {label}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed3426",
   "metadata": {},
   "source": [
    "## 8. Save All Files\n",
    "\n",
    "Save conversations and embeddings to `/kaggle/working/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"STEP 5: Saving Files\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\\n\")\n",
    "\n",
    "# Save train conversations\n",
    "train_path = output_dir / \"cora_train_node_data.jsonl\"\n",
    "with open(train_path, 'w', encoding='utf-8') as f:\n",
    "    for conv in train_conversations:\n",
    "        f.write(json.dumps(conv) + '\\n')\n",
    "train_size = os.path.getsize(train_path) / (1024**2)\n",
    "print(f\"âœ“ Saved: {train_path.name}\")\n",
    "print(f\"  Samples: {len(train_conversations):,}\")\n",
    "print(f\"  Size: {train_size:.2f} MB\")\n",
    "\n",
    "# Save test conversations\n",
    "test_path = output_dir / \"cora_test_node_data.jsonl\"\n",
    "with open(test_path, 'w', encoding='utf-8') as f:\n",
    "    for conv in test_conversations:\n",
    "        f.write(json.dumps(conv) + '\\n')\n",
    "test_size = os.path.getsize(test_path) / (1024**2)\n",
    "print(f\"\\nâœ“ Saved: {test_path.name}\")\n",
    "print(f\"  Samples: {len(test_conversations):,}\")\n",
    "print(f\"  Size: {test_size:.2f} MB\")\n",
    "\n",
    "# Save base node embeddings\n",
    "node_emb_path = output_dir / \"node_embeddings.pt\"\n",
    "torch.save(node_embeddings, node_emb_path)\n",
    "node_emb_size = os.path.getsize(node_emb_path) / (1024**2)\n",
    "print(f\"\\nâœ“ Saved: {node_emb_path.name}\")\n",
    "print(f\"  Shape: {node_embeddings.shape}\")\n",
    "print(f\"  Size: {node_emb_size:.2f} MB\")\n",
    "\n",
    "# Save multi-hop embeddings\n",
    "multi_hop_path = output_dir / \"multi_hop_graph_embedding.pt\"\n",
    "torch.save(multi_hop_embs, multi_hop_path)\n",
    "multi_hop_size = os.path.getsize(multi_hop_path) / (1024**2)\n",
    "print(f\"\\nâœ“ Saved: {multi_hop_path.name}\")\n",
    "print(f\"  Shape: {multi_hop_embs.shape}\")\n",
    "print(f\"  Size: {multi_hop_size:.2f} MB\")\n",
    "\n",
    "# Calculate total size\n",
    "total_size = train_size + test_size + node_emb_size + multi_hop_size\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… ALL FILES SAVED SUCCESSFULLY!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total size: {total_size:.2f} MB\")\n",
    "print(f\"Location: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931aef8",
   "metadata": {},
   "source": [
    "## 9. Summary and Download Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7adb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"âœ… PREPARATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary:\")\n",
    "print(f\"  â€¢ Dataset: Cora Citation Network\")\n",
    "print(f\"  â€¢ Total nodes: {data.num_nodes:,}\")\n",
    "print(f\"  â€¢ Train samples: {len(train_conversations):,}\")\n",
    "print(f\"  â€¢ Test samples: {len(test_conversations):,}\")\n",
    "print(f\"  â€¢ Classes: {len(data.label_texts)}\")\n",
    "print(f\"  â€¢ Multi-hop embeddings: {multi_hop_embs.shape}\")\n",
    "print(f\"  â€¢ Total output size: {total_size:.2f} MB\")\n",
    "\n",
    "print(\"\\nðŸ“¥ Download Instructions:\")\n",
    "print(\"  1. Click 'Output' tab on the right sidebar\")\n",
    "print(\"  2. Click 'Download All' to get cora_gwm_data.zip\")\n",
    "print(\"  3. Or download files individually:\")\n",
    "\n",
    "for file in sorted(output_dir.glob(\"*\")):\n",
    "    size_mb = os.path.getsize(file) / (1024**2)\n",
    "    print(f\"     â€¢ {file.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\nðŸš€ Next Steps:\")\n",
    "print(\"  1. Download the files from Kaggle\")\n",
    "print(\"  2. Upload to your training environment\")\n",
    "print(\"  3. Update file paths in GWM-E training script\")\n",
    "print(\"  4. Run training:\")\n",
    "print(\"     python train.py \\\\\")\n",
    "print(\"       --train_jsonl cora_train_node_data.jsonl \\\\\")\n",
    "print(\"       --test_jsonl cora_test_node_data.jsonl \\\\\")\n",
    "print(\"       --embedding_path multi_hop_graph_embedding.pt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Show example conversation\n",
    "print(\"\\nðŸ“ Example Conversation:\")\n",
    "print(\"-\"*70)\n",
    "example = json.dumps(train_conversations[0], indent=2)\n",
    "if len(example) > 600:\n",
    "    print(example[:600] + \"\\n...\")\n",
    "else:\n",
    "    print(example)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Notebook completed successfully! ðŸŽ‰\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047417d",
   "metadata": {},
   "source": [
    "## Optional: Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47955a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification\n",
    "print(\"Verifying saved files...\\n\")\n",
    "\n",
    "# Load and check embeddings\n",
    "loaded_embs = torch.load(multi_hop_path)\n",
    "print(f\"âœ“ Multi-hop embeddings: {loaded_embs.shape}\")\n",
    "assert loaded_embs.shape == multi_hop_embs.shape\n",
    "\n",
    "# Load and check conversations\n",
    "with open(train_path, 'r') as f:\n",
    "    train_lines = f.readlines()\n",
    "print(f\"âœ“ Train conversations: {len(train_lines)} lines\")\n",
    "assert len(train_lines) == len(train_conversations)\n",
    "\n",
    "with open(test_path, 'r') as f:\n",
    "    test_lines = f.readlines()\n",
    "print(f\"âœ“ Test conversations: {len(test_lines)} lines\")\n",
    "assert len(test_lines) == len(test_conversations)\n",
    "\n",
    "print(\"\\nâœ… All files verified successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
