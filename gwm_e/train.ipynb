{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6023893",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Check GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f04ff",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Adjust these paths and hyperparameters based on your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths (update these to your file locations)\n",
    "DATA_CONFIG = {\n",
    "    'train_jsonl': '../data/cora/cora_train_node_data.jsonl',\n",
    "    'test_jsonl': '../data/cora/cora_test_node_data.jsonl',\n",
    "    'embedding_path': '../data/cora/multi_hop_graph_embedding.pt',\n",
    "}\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'llama_model': 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    'graph_embedding_dim': 2048,\n",
    "    'projector_hidden_dim': 4096,\n",
    "    'num_hops': 5,\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'batch_size': 8,\n",
    "    'gradient_accumulation_steps': 4,  # Effective batch size = 8 * 4 = 32\n",
    "    'learning_rate': 2e-4,\n",
    "    'num_epochs': 10,\n",
    "    'warmup_steps': 100,\n",
    "    'num_workers': 4,\n",
    "    'output_dir': './checkpoints',\n",
    "    'save_every': 1,  # Save every N epochs\n",
    "}\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(\"\\nData:\")\n",
    "for k, v in DATA_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nModel:\")\n",
    "for k, v in MODEL_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nTraining:\")\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nDevice: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6806b09c",
   "metadata": {},
   "source": [
    "## 3. Load Model and Data\n",
    "\n",
    "This will load the GWM-E model with frozen LLaMA and trainable projector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbf753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model and dataset classes\n",
    "from model import GWM_E\n",
    "from dataset import create_dataloaders\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"Loading GWM-E Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize model\n",
    "model = GWM_E(\n",
    "    llama_model_path=MODEL_CONFIG['llama_model'],\n",
    "    graph_embedding_dim=MODEL_CONFIG['graph_embedding_dim'],\n",
    "    projector_hidden_dim=MODEL_CONFIG['projector_hidden_dim'],\n",
    "    num_hops=MODEL_CONFIG['num_hops'],\n",
    "    freeze_llm=True,  # Only train projector\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Model loaded successfully!\")\n",
    "print(f\"  LLaMA parameters: {sum(p.numel() for p in model.llm.parameters()) / 1e9:.2f}B (frozen)\")\n",
    "print(f\"  Projector parameters: {sum(p.numel() for p in model.projector.parameters()) / 1e6:.2f}M (trainable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06902acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"Loading Datasets\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, test_loader = create_dataloaders(\n",
    "    train_jsonl=DATA_CONFIG['train_jsonl'],\n",
    "    test_jsonl=DATA_CONFIG['test_jsonl'],\n",
    "    embedding_path=DATA_CONFIG['embedding_path'],\n",
    "    tokenizer=model.tokenizer,\n",
    "    batch_size=TRAINING_CONFIG['batch_size'],\n",
    "    num_workers=TRAINING_CONFIG['num_workers'],\n",
    "    num_hops=MODEL_CONFIG['num_hops'],\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Datasets loaded successfully!\")\n",
    "print(f\"  Training samples: {len(train_loader.dataset):,}\")\n",
    "print(f\"  Test samples: {len(test_loader.dataset):,}\")\n",
    "print(f\"  Training batches: {len(train_loader):,}\")\n",
    "print(f\"  Test batches: {len(test_loader):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9133399e",
   "metadata": {},
   "source": [
    "## 4. Setup Training\n",
    "\n",
    "Configure optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"Setting up Training\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(TRAINING_CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save training config\n",
    "config_path = output_dir / \"training_config.json\"\n",
    "all_config = {**DATA_CONFIG, **MODEL_CONFIG, **TRAINING_CONFIG}\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(all_config, f, indent=2)\n",
    "print(f\"âœ“ Saved config to: {config_path}\")\n",
    "\n",
    "# Setup optimizer (only for projector parameters)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.projector.parameters(),\n",
    "    lr=TRAINING_CONFIG['learning_rate'],\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "print(f\"âœ“ Optimizer: AdamW (lr={TRAINING_CONFIG['learning_rate']})\")\n",
    "\n",
    "# Calculate total training steps\n",
    "total_steps = len(train_loader) * TRAINING_CONFIG['num_epochs'] // TRAINING_CONFIG['gradient_accumulation_steps']\n",
    "print(f\"âœ“ Total training steps: {total_steps:,}\")\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=TRAINING_CONFIG['warmup_steps'],\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "print(f\"âœ“ Scheduler: Linear warmup ({TRAINING_CONFIG['warmup_steps']} steps) + decay\")\n",
    "\n",
    "print(f\"\\nâœ“ Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e7eb0e",
   "metadata": {},
   "source": [
    "## 5. Training Functions\n",
    "\n",
    "Define training and evaluation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fef823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, scheduler, epoch, gradient_accumulation_steps, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        Average loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # Move to device\n",
    "        multi_hop_embedding = batch['multi_hop_embedding'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, loss = model(\n",
    "            multi_hop_embeddings=multi_hop_embedding,\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "        \n",
    "        # Scale loss for gradient accumulation\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights every gradient_accumulation_steps\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.projector.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Track loss\n",
    "        total_loss += loss.item() * gradient_accumulation_steps\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item() * gradient_accumulation_steps:.4f}\",\n",
    "            'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test set.\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss, accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            # Move to device\n",
    "            multi_hop_embedding = batch['multi_hop_embedding'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, loss = model(\n",
    "                multi_hop_embeddings=multi_hop_embedding,\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy (on non-masked tokens)\n",
    "            mask = labels != -100\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            correct += ((predictions == labels) & mask).sum().item()\n",
    "            total += mask.sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "print(\"âœ“ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df8a22",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "Run the main training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fe854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*25 + \"STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_accuracy = 0\n",
    "training_history = []\n",
    "\n",
    "for epoch in range(1, TRAINING_CONFIG['num_epochs'] + 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch}/{TRAINING_CONFIG['num_epochs']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        epoch=epoch,\n",
    "        gradient_accumulation_steps=TRAINING_CONFIG['gradient_accumulation_steps'],\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_accuracy = evaluate(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    # Log results\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch} Results:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Train Loss:     {train_loss:.4f}\")\n",
    "    print(f\"  Test Loss:      {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Save history\n",
    "    training_history.append({\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "    })\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if epoch % TRAINING_CONFIG['save_every'] == 0 or test_accuracy > best_accuracy:\n",
    "        checkpoint_path = output_dir / f\"projector_epoch_{epoch}.pt\"\n",
    "        model.save_projector(str(checkpoint_path))\n",
    "        print(f\"  âœ“ Saved checkpoint: {checkpoint_path.name}\")\n",
    "        \n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_path = output_dir / \"projector_best.pt\"\n",
    "            model.save_projector(str(best_path))\n",
    "            print(f\"  â­ New best accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Save training history\n",
    "history_path = output_dir / \"training_history.json\"\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*20 + \"âœ… TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best test accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"Checkpoints saved to: {output_dir}\")\n",
    "print(f\"Training history saved to: {history_path}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3500d",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract metrics\n",
    "epochs = [h['epoch'] for h in training_history]\n",
    "train_losses = [h['train_loss'] for h in training_history]\n",
    "test_losses = [h['test_loss'] for h in training_history]\n",
    "test_accuracies = [h['test_accuracy'] for h in training_history]\n",
    "\n",
    "# Create plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(epochs, train_losses, 'b-o', label='Train Loss')\n",
    "ax1.plot(epochs, test_losses, 'r-o', label='Test Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(epochs, [acc * 100 for acc in test_accuracies], 'g-o', label='Test Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Saved training curves to: {output_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25ef97",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4293f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*25 + \"TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Results:\")\n",
    "print(f\"  Best Test Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"  Final Train Loss:   {training_history[-1]['train_loss']:.4f}\")\n",
    "print(f\"  Final Test Loss:    {training_history[-1]['test_loss']:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Training Progress:\")\n",
    "print(f\"  Initial Accuracy: {training_history[0]['test_accuracy']:.4f} ({training_history[0]['test_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Final Accuracy:   {training_history[-1]['test_accuracy']:.4f} ({training_history[-1]['test_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Improvement:      {(training_history[-1]['test_accuracy'] - training_history[0]['test_accuracy']):.4f} ({(training_history[-1]['test_accuracy'] - training_history[0]['test_accuracy'])*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved Files:\")\n",
    "print(f\"  â€¢ Best model: {output_dir / 'projector_best.pt'}\")\n",
    "print(f\"  â€¢ Training history: {output_dir / 'training_history.json'}\")\n",
    "print(f\"  â€¢ Training curves: {output_dir / 'training_curves.png'}\")\n",
    "print(f\"  â€¢ Config: {output_dir / 'training_config.json'}\")\n",
    "\n",
    "print(f\"\\nðŸš€ Next Steps:\")\n",
    "print(f\"  1. Run inference notebook to evaluate on test set\")\n",
    "print(f\"  2. Or run: python inference.py \\\\\")\n",
    "print(f\"       --test_jsonl {DATA_CONFIG['test_jsonl']} \\\\\")\n",
    "print(f\"       --embedding_path {DATA_CONFIG['embedding_path']} \\\\\")\n",
    "print(f\"       --projector_checkpoint {output_dir / 'projector_best.pt'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b27952",
   "metadata": {},
   "source": [
    "## Optional: Test a Single Prediction\n",
    "\n",
    "Quick test to see model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from test set\n",
    "test_sample = test_loader.dataset[0]\n",
    "test_conv = test_loader.dataset.conversations[0]\n",
    "\n",
    "print(\"Testing model on a single example...\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"Sample Input:\")\n",
    "print(\"=\"*70)\n",
    "for turn in test_conv['conversations']:\n",
    "    role = turn['from']\n",
    "    message = turn['value'][:200] + \"...\" if len(turn['value']) > 200 else turn['value']\n",
    "    print(f\"{role.upper()}: {message}\\n\")\n",
    "\n",
    "# Prepare inputs\n",
    "multi_hop_emb = test_sample['multi_hop_embedding'].unsqueeze(0).to(device)\n",
    "input_ids = test_sample['input_ids'].unsqueeze(0).to(device)\n",
    "attention_mask = test_sample['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "# Generate prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        multi_hop_embeddings=multi_hop_emb,\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.1,\n",
    "    )\n",
    "\n",
    "# Decode\n",
    "input_length = input_ids.shape[1]\n",
    "generated = model.tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Model Prediction:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ASSISTANT: {generated}\\n\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
